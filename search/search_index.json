{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting Started with the Emotion Recognition Pipeline","text":"<p>Welcome to the Emotion Recognition Pipeline! This guide will help you install, configure, and use the pipeline to analyze movement data and recognize emotions efficiently.</p>"},{"location":"#1-installation","title":"1. Installation","text":""},{"location":"#prerequisites","title":"Prerequisites","text":"<ul> <li>Python: Version 3.8 or higher.</li> <li>Environment: It is recommended to create a virtual environment for managing dependencies.</li> </ul> <pre><code>python -m venv env\nsource env/bin/activate  # On Windows: env\\Scripts\\activate\n</code></pre>"},{"location":"#steps","title":"Steps","text":"<ol> <li> <p>Clone the repository:    <pre><code>git clone https://github.com/&lt;your-username&gt;/emotion-recognition-pipeline.git\ncd emotion-recognition-pipeline\n</code></pre></p> </li> <li> <p>Install dependencies:    <pre><code>pip install -r requirements.txt\n</code></pre></p> </li> </ol>"},{"location":"#2-understanding-movement-data","title":"2. Understanding Movement Data","text":"<p>Movement data refers to the information captured about how a body moves through space. It is typically recorded using sensors like accelerometers and gyroscopes, which measure changes in velocity and angular rotation. For example, smartwatches and fitness trackers collect movement data in three axes with a sampling rate:</p> <ul> <li> <p>X-axis: Forward and backward movement</p> </li> <li> <p>Y-axis: Side-to-side movement</p> </li> <li> <p>Z-axis: Up and down movement</p> </li> <li> <p>Sampling Rate: Devices record data at a specific frequency, like 25Hz (25 data points per second), to ensure smooth and continuous tracking.</p> </li> </ul> <p>The recorded data is stored in raw formats, often as time-series data with timestamps and helps us understand physical activity patterns, postures, and even subtle gestures.</p>"},{"location":"#3-understanding-emotions","title":"3. Understanding Emotions","text":"<p>Emotions are psychological and physiological responses that can be categorized using different models. A widespread model is the 2D Valence-Arousal Model by Russell with these axes:</p> <ul> <li>Arousal: Refers to the intensity of the emotion, ranging from calm (low arousal) to excited (high arousal).</li> <li>Valence: Refers to the positivity or negativity of the emotion, ranging from unpleasant (negative valence) to pleasant (positive valence).</li> </ul> <p></p> <p>There are also other emotion models:</p> <ul> <li> <p>Ekman's six fundamental types of emotions</p> </li> <li> <p>The Positive and Negative Affect Schedule (PANAS) Model</p> </li> </ul>"},{"location":"#4-movement-data-processing","title":"4. Movement Data Processing","text":"<p>Movement Data can be processed in these 4 steps: </p> <p>Data Acquisition, Data Preprocessing, Feature Extraction, and Model Training &amp; Evaluation.</p> <p></p>"},{"location":"#5-the-user-friendly-pipeline-to-recognize-emotions-with-movement-data","title":"5. The User-Friendly Pipeline to Recognize Emotions with Movement Data","text":"<p>A pipeline was developed to make this process more efficient, reusable, consistent and automated.</p>"},{"location":"#51-what-is-a-pipeline-in-general","title":"5.1 What is a Pipeline in general?","text":"<p>In data processing and machine learning, a pipeline is a structured sequence of steps to transform raw input data into meaningful outputs, for example classifications. Each step in a pipeline performs a specific function, and the output of one step serves as the input for the next.</p> <p></p>"},{"location":"#52-structure-of-the-emotion-recognition-pipeline","title":"5.2 Structure of the Emotion Recognition Pipeline","text":"<p>This Pipeline consists out of multiple smaller pipelines which can be used seperately for different purposes and work as checkpoints in your experimental workflow.</p> <p></p>"},{"location":"#6general-workflow-using-the-pipeline","title":"6.General Workflow using the Pipeline","text":""},{"location":"#61-how-to-combine-dataframes","title":"6.1. How to combine Dataframes","text":"<p>If you want to train a model on a given dataset, you will like have two seperate datasets, one containing the Raw Accelerometer Data and second a Dataset with the labeled data. You can now use this predefined pipeline to combine those datasets. You can choose which size the timewindow should be. A timewindow is the amount of time before and after the emotion was labeled. Also you will have to </p>"},{"location":"#62-how-to-extract-features","title":"6.2. How to extract Features","text":""},{"location":"#63-how-to-train-a-model","title":"6.3 How to train a Model","text":""},{"location":"#64-how-to-classify-movement-data","title":"6.4 How to classify Movement Data","text":""},{"location":"classes_classify_movement_data/","title":"Classify Movement Data","text":"<p>This class is designed to analyze movement data using a pre-trained model. It takes movement data as input, predicts emotional states (like mood or stress level) based on the data, and then saves the results to a file. It works automatically, so you don't need to know how the model itself works.</p>"},{"location":"classes_classify_movement_data/#step-by-step-explanation","title":"Step-by-Step Explanation:","text":"<ol> <li>Loading the Pre-Trained Model:<ul> <li>The class uses a pre-trained machine learning model (a program that has already learned how to make predictions based on past data).</li> <li>When you run this class for the first time, it finds and loads this model from a file.</li> </ul> </li> <li>Processing Movement Data:<ul> <li>The input data (like movement from a smartwatch) must already be prepared and organized into a table of numbers (called \"features\").</li> <li>This class uses the loaded model to analyze the movement data and predict emotions or states based on it.</li> </ul> </li> <li>Adding Predictions:<ul> <li>Once predictions are made, the class adds a new column to your table. This column contains the predicted emotions for each row of data.</li> </ul> </li> <li>Saving the Results:<ul> <li>The updated table (with the predictions added) is saved as a file. This file is easy to open in programs like Excel or similar tools.</li> <li>The file's name includes the \"window length\" (a setting for how the data is divided into chunks), making it easy to identify later.</li> </ul> </li> <li>Messages:<ul> <li>The class shows messages like \"Model loaded\" and \"Data classified successfully\" to confirm that everything is working as expected.</li> </ul> </li> </ol>"},{"location":"classes_create_combined_dataframe/","title":"Create Combined Dataframe","text":"<p>This class combines two datasets: self-reported emotion data (like arousal and valence ratings) and movement data (from a smartwatch's accelerometer). It matches these two types of data based on the time they were recorded and saves the combined result in a new file. This is helpful for analyzing how emotions relate to movement patterns.</p>"},{"location":"classes_create_combined_dataframe/#step-by-step-explanation","title":"Step-by-Step Explanation:","text":"<ol> <li>Input Data:<ul> <li>The class works with two datasets:<ul> <li>Self-Reports: A table where participants record their emotions (like arousal or valence) at specific times.</li> <li>Movement Data: A table of movement information (accelerometer data), recorded at different times.</li> </ul> </li> <li>These datasets must be provided as inputs when using this class.</li> </ul> </li> <li>Label Selection:<ul> <li>You can choose which emotions (labels) to include, like arousal and valence. If you don\u2019t specify, it defaults to using these two labels.</li> </ul> </li> <li>Filtering the Data:<ul> <li>It removes any rows in the self-report data where the labels are missing or invalid.</li> <li>Ensures that the labels you want to analyze exist in the dataset.</li> </ul> </li> <li>Matching Movement and Emotion Data:<ul> <li>For each self-reported emotion entry, the class looks for movement data recorded in a specific time range around that entry (called a \"time window\"). This links movement patterns with the emotions reported at a similar time.</li> </ul> </li> <li>Combining the Data:<ul> <li>It creates a new table (or DataFrame) where each row includes:<ul> <li>Participant Information: Like their ID.</li> <li>Emotion Labels: For example, arousal and valence ratings.</li> <li>Movement Data: Accelerometer values (x, y, z) recorded at specific times.</li> </ul> </li> <li>Each row connects a participant's emotion and movement data based on the matching time window.</li> </ul> </li> <li>Group Identifier:<ul> <li>A unique \"group ID\" is added to each combined entry to indicate which participant and self-report it belongs to.</li> </ul> </li> <li>Saving the Results:<ul> <li>The combined data is saved as a file. The file name includes details like the size of the time window and which labels were used. This makes it easy to identify later.</li> </ul> </li> <li>Friendly Messages:<ul> <li>The class shows messages at different stages (e.g., \u201cProcessing label: arousal\u201d or \u201cCombined dataframe exported successfully\u201d), so you know what\u2019s happening.</li> </ul> </li> </ol>"},{"location":"classes_extract_features/","title":"Extract Features","text":"<p>This class analyzes movement data (like accelerometer readings from a smartwatch) by dividing it into time chunks (\"windows\") and calculating features (mathematical summaries) for each chunk. These features help in understanding patterns in movement, such as average speed, variability, or frequency of movement. The results are saved in a file for further analysis or use in machine learning.</p>"},{"location":"classes_extract_features/#step-by-step-explanation","title":"Step-by-Step Explanation:","text":"<ol> <li>Input Data:<ul> <li>The input is a table containing accelerometer data, which measures movement along three axes: x, y, and z.</li> <li>The data is recorded continuously, so this class divides it into manageable time chunks, called \"windows.\"</li> </ul> </li> <li>Window Creation:<ul> <li>Each window represents a specific time span of movement (e.g., 1 minute).</li> <li>A \"step size\" determines how much the window moves forward for the next chunk (e.g., every 30 seconds).</li> <li>This ensures all the data is analyzed efficiently.</li> </ul> </li> <li>Feature Extraction:<ul> <li>The class calculates a variety of features for each window. These features summarize the movement data and make it easier to analyze or use in machine learning.</li> <li>Features are grouped into domains, including:<ul> <li>Time Domain Features: Basic statistics like average movement, variability, and extremes.</li> <li>Spatial Features: Measures like angles (tilt) and correlations between axes.</li> <li>Frequency Domain Features: Patterns in how often movement occurs (e.g., fast vibrations vs. slow sways).</li> <li>Statistical Features: Percentiles to capture movement range.</li> <li>Wavelet Features: A way to break movement into simple patterns for analysis.</li> </ul> </li> <li>Users can choose which domains to include or calculate all features if no preference is set.</li> </ul> </li> <li>Magnitude Calculation:<ul> <li>The class can also calculate features for the \"magnitude,\" which combines x, y, and z movements into one overall measure of intensity.</li> </ul> </li> <li>Combining Features with Labels:<ul> <li>If emotion labels (like arousal and valence) are available, they are added to the features for each window. This makes it possible to link movement patterns with emotions.</li> </ul> </li> <li>Saving the Results:<ul> <li>The calculated features for all windows are saved in a file. The file name includes details like the window size, step size, and selected domains for easy identification.</li> </ul> </li> <li>Friendly Messages:<ul> <li>Messages like \"All features extracted successfully\" are displayed to let the user know the process is complete.</li> </ul> </li> </ol>"},{"location":"classes_import_data/","title":"Import Data","text":"<p>This class is responsible for importing data that will be analyzed. Depending on what you want to analyze, it can load different types of data:</p> <ul> <li>Raw accelerometer data: Movement data from a smartwatch.</li> <li>Self-report data: Information provided by participants, like emotions or experiences.</li> <li>Combined data: A dataset where accelerometer and self-report data are already matched.</li> <li>Pre-extracted features: If features (summaries of movement data) have already been calculated, it can load those instead.</li> </ul> <p>This flexibility allows you to start your analysis from different stages, depending on your needs.</p>"},{"location":"classes_import_data/#step-by-step-explanation","title":"Step-by-Step Explanation:","text":"<ol> <li>Customizable Data Loading:<ul> <li>You decide which type of data you want to work with by setting the appropriate options (e.g., <code>use_accel</code>, <code>use_reports</code>, <code>use_combined</code>, <code>use_features</code>).</li> <li>The class automatically chooses the correct file paths for the selected data, based on settings in the configuration file.</li> </ul> </li> <li>Importing Features:<ul> <li>If you\u2019ve already extracted features (summaries of movement data), the class loads that data from a file.</li> <li>This is useful if you want to skip the feature extraction step and jump straight into analysis.</li> </ul> </li> <li>Importing Combined Data:<ul> <li>If you\u2019ve already matched accelerometer and self-report data, the class loads this pre-combined dataset.</li> <li>This saves time by skipping the data-matching step.</li> </ul> </li> <li>Importing Raw Data:<ul> <li>If no combined data or features are available, the class loads:<ul> <li>Raw accelerometer data: Measurements of movement (x, y, z axes).</li> <li>Self-report data (if available): Participant-provided information, such as emotions or labels.</li> </ul> </li> </ul> </li> <li>Error Handling:<ul> <li>If you try to load raw accelerometer data without specifying its file path, the class raises an error to let you know that a path is required.</li> </ul> </li> <li>Output:<ul> <li>Depending on what you\u2019re working with, the class outputs:<ul> <li>A single dataset (features, combined data, or accelerometer data alone).</li> <li>Two datasets (accelerometer data and self-report data), if both are available.</li> </ul> </li> </ul> </li> <li>Friendly Messages:<ul> <li>The class prints messages to let you know which data has been successfully loaded, such as:<ul> <li>\u201cFeatures dataframe imported successfully.\u201d</li> <li>\u201cRaw accelerometer data imported successfully.\u201d</li> </ul> </li> </ul> </li> </ol>"},{"location":"classes_lowpass_filter/","title":"Low-Pass Filter","text":"<p>This class is designed to smooth out accelerometer data by removing high-frequency noise (quick and insignificant changes in movement). It uses a mathematical technique called a low-pass filter to focus on slower, meaningful movement patterns. This is useful when analyzing movement data because it makes trends and significant motions clearer.</p>"},{"location":"classes_lowpass_filter/#step-by-step-explanation","title":"Step-by-Step Explanation:","text":"<ol> <li>Input Data:<ul> <li>The input is a table (DataFrame) with three columns: x, y, z. These represent movement measurements along three axes.</li> </ul> </li> <li>Low-Pass Filter:<ul> <li>The filter removes fast, noisy signals from the data. For example:<ul> <li>If you\u2019re walking, the filter keeps the steady up-and-down motion of your steps but removes tiny vibrations caused by your device or environment.</li> </ul> </li> </ul> </li> <li>How It Works:<ul> <li>A mathematical function (called a Butterworth filter) is applied to the data.</li> <li>It keeps movement data below a certain speed (frequency), determined by the cutoff frequency. Movements faster than this speed are considered noise and are removed.</li> </ul> </li> <li>Filter Settings:<ul> <li>Cutoff Frequency: The speed at which the filter decides whether to keep or remove a signal (e.g., 5 Hz means it keeps motions slower than 5 cycles per second).</li> <li>Sampling Rate: The rate at which the device records movement data (e.g., 25 Hz means 25 data points per second).</li> <li>Filter Order: Determines the sharpness of the filtering. A higher order makes the cutoff more precise.</li> </ul> </li> <li>Smoothing the Data:<ul> <li>The class applies the low-pass filter to the x, y, and z columns of the data, smoothing them to remove noise.</li> </ul> </li> <li>Output:<ul> <li>The filtered data is returned as a table (DataFrame) with the same structure as the input.</li> <li>The smoothed columns (x, y, z) are ready for further analysis.</li> </ul> </li> <li>Error Handling:<ul> <li>If the input data doesn\u2019t include the required columns (x, y, z), the class raises an error to ensure proper usage.</li> </ul> </li> <li>Friendly Messages:<ul> <li>After the filter is applied, the class prints a message: \u201cLow-pass filter applied successfully,\u201d so the user knows the process is complete.</li> </ul> </li> </ol>"},{"location":"classes_pca_handler/","title":"Principal Component Analysis (PCA)","text":"<p>This class handles Principal Component Analysis (PCA), a mathematical method used to simplify large datasets. PCA reduces the number of variables (columns) in the data while keeping as much important information as possible. It\u2019s especially helpful when working with complex data, like features extracted from accelerometer readings.</p>"},{"location":"classes_pca_handler/#step-by-step-explanation","title":"Step-by-Step Explanation:","text":"<ol> <li>What is PCA?<ul> <li>PCA transforms the data into a smaller set of \"principal components.\" These are new variables that summarize the original data.</li> <li>For example, if you have 100 columns, PCA can reduce it to just a few components that still capture most of the data's variation.</li> </ul> </li> <li>Input Data:<ul> <li>The input is a table (DataFrame) with many columns (features).</li> </ul> </li> <li>When PCA is Applied:<ul> <li>The class applies PCA only if <code>apply_pca</code> is set to <code>True</code>. If not, the data remains unchanged.</li> <li>Variance: You can specify how much of the original data\u2019s information (variance) you want to keep. For example:<ul> <li><code>variance=0.95</code> means PCA will retain 95% of the data's important information.</li> </ul> </li> </ul> </li> <li>How It Works:<ul> <li>During fitting (<code>fit</code> method):<ul> <li>The class calculates the PCA transformation based on the input data.</li> <li>This identifies which components (combinations of columns) best summarize the data.</li> </ul> </li> <li>During transformation (<code>transform</code> method):<ul> <li>The data is transformed into its principal components, reducing the number of columns.</li> </ul> </li> </ul> </li> <li>Output:<ul> <li>If PCA is applied, the output is a simplified table (DataFrame) with fewer columns (principal components).</li> <li>If PCA is not applied, the data remains the same.</li> </ul> </li> <li>Key Features:<ul> <li>Automatic Adjustment: PCA automatically determines how many components to use based on the <code>variance</code> value.</li> <li>Flexibility: You can turn PCA on or off using <code>apply_pca</code>.</li> </ul> </li> <li>Error Handling:<ul> <li>If PCA is enabled but hasn't been \"fitted\" to the data, the class ensures that an error doesn\u2019t occur by skipping PCA.</li> </ul> </li> </ol>"},{"location":"classes_scalexyz_data/","title":"Scale Data","text":"<p>This class scales accelerometer data to make the measurements more consistent and easier to analyze. Scaling adjusts the values of the data without changing its overall patterns, which is especially important when working with machine learning models.</p>"},{"location":"classes_scalexyz_data/#step-by-step-explanation","title":"Step-by-Step Explanation:","text":"<ol> <li>Input Data:<ul> <li>The input is a table (DataFrame) with three columns: x, y, z. These represent movement measurements along three axes.</li> </ul> </li> <li>Why Scaling Is Important:<ul> <li>Accelerometer values can have different ranges (e.g., x might range from -10 to 10, while z might range from -1 to 1).</li> <li>Scaling ensures that all axes are on the same scale, which helps:<ul> <li>Prevent certain axes from dominating the analysis.</li> <li>Improve the performance of machine learning algorithms.</li> </ul> </li> </ul> </li> <li>Scaling Methods:<ul> <li>The class offers three scaling options:<ol> <li>Standard Scaling (<code>standard</code>):<ul> <li>Adjusts the data so it has a mean of 0 and a standard deviation of 1. This centers the data and normalizes its spread.</li> </ul> </li> <li>Min-Max Scaling (<code>minmax</code>):<ul> <li>Adjusts the data to fit within a range of 0 to 1. This is useful when you want all values to be non-negative and comparable.</li> </ul> </li> <li>No Scaling (<code>none</code>):<ul> <li>Leaves the data unchanged. This is useful if scaling is not necessary for your analysis.</li> </ul> </li> </ol> </li> </ul> </li> <li>How It Works:<ul> <li>During transformation (<code>transform</code> method):<ul> <li>The class identifies the x, y, z columns in the input data.</li> <li>Depending on the scaling method:<ul> <li>It applies the chosen scaling method to these columns.</li> <li>If <code>none</code> is selected, it skips scaling and returns the data as it is.</li> </ul> </li> </ul> </li> </ul> </li> <li>Output:<ul> <li>The output is the same table (DataFrame) but with the x, y, z columns scaled according to the selected method.</li> </ul> </li> <li>Error Handling:<ul> <li>If an invalid scaling method is provided, the class raises an error, ensuring only valid options (<code>standard</code>, <code>minmax</code>, or <code>none</code>) are accepted.</li> </ul> </li> <li>Friendly Messages:<ul> <li>After scaling is applied, the class prints: \u201cData scaled successfully,\u201d confirming the operation is complete.</li> </ul> </li> </ol>"},{"location":"classes_train_model/","title":"Train Model","text":"<p>This class is responsible for training a machine learning model to classify emotions or behaviors based on movement data. It automates the entire training process, including preparing the data, finding the best model settings, evaluating performance, and saving the results.</p>"},{"location":"classes_train_model/#step-by-step-explanation","title":"Step-by-Step Explanation:","text":"<ol> <li>Input Data:<ul> <li>The input is a dataset with:<ul> <li>Features: Data that describes movements (e.g., accelerometer readings).</li> <li>Target Label: The emotion or state you want the model to predict (e.g., arousal or valence).</li> </ul> </li> </ul> </li> <li>Target Label Encoding:<ul> <li>The target label (e.g., \"high,\" \"medium,\" \"low\") is converted into numbers (e.g., 0, 1, 2) so the model can understand it.</li> <li>A mapping is created to show how the original labels correspond to these numbers.</li> </ul> </li> <li>Model Selection:<ul> <li>You can choose from three machine learning models:<ul> <li>XGBoost: Great for handling complex datasets.</li> <li>Support Vector Machine (SVM): Works well for smaller datasets.</li> <li>Random Forest: Easy to use and interpretable.</li> </ul> </li> <li>This choice is specified in the configuration file.</li> </ul> </li> <li>Hyperparameter Tuning:<ul> <li>Models have settings (called hyperparameters) that affect how they learn.</li> <li>The class automatically tries different combinations of these settings to find the best one using Bayesian optimization. This saves time compared to manual tuning.</li> </ul> </li> <li>Cross-Validation:<ul> <li>The class uses Stratified Group K-Fold Cross-Validation to test the model\u2019s performance during training.</li> <li>This ensures the model is evaluated fairly and works well across different groups of data (e.g., participants).</li> </ul> </li> <li>Model Training:<ul> <li>The best settings from hyperparameter tuning are used to train the model.</li> <li>The class outputs the model\u2019s accuracy and a detailed classification report (e.g., how well it predicts each label).</li> </ul> </li> <li>Saving Results:<ul> <li>The class saves:<ul> <li>The trained model (for future use).</li> <li>Metadata, such as:<ul> <li>The best settings.</li> <li>The model's accuracy.</li> <li>Label mappings and feature importances (if available).</li> </ul> </li> <li>A detailed classification report as a JSON file.</li> </ul> </li> </ul> </li> <li>Output Files:<ul> <li>The saved files include:<ul> <li>Model File: Contains the trained model.</li> <li>Metadata File: Includes information about the model\u2019s performance and settings.</li> <li>Classification Report: Shows how well the model predicts each label.</li> </ul> </li> </ul> </li> </ol>"},{"location":"config/","title":"Config","text":""},{"location":"config/#paths-for-import-data","title":"Paths for Import Data","text":"<ol> <li><code>accel_path</code>:<ul> <li>Path to the accelerometer data file.</li> <li>Contains raw movement data (x, y, z axes) recorded by a device (e.g., smartwatch).</li> <li>Example: <code>single_participant_positive_high.csv</code> contains accelerometer data for a specific participant.</li> </ul> </li> <li><code>reports_path</code>:<ul> <li>Path to the self-reports data file.</li> <li>Includes participant-reported labels, such as emotional states (e.g., valence, arousal).</li> </ul> </li> <li><code>combined_data_path</code>:<ul> <li>Path to the combined data file.</li> <li>This file matches accelerometer data with self-reports, linking movements with emotions over a specific time window.</li> </ul> </li> <li><code>features_data_path</code>:<ul> <li>Path to the features data file.</li> <li>Contains pre-calculated features extracted from accelerometer data for analysis, so feature extraction can be skipped.</li> </ul> </li> <li><code>model_path</code>:<ul> <li>Path to a pre-trained machine learning model.</li> <li>Used for predicting emotional states based on accelerometer data (e.g., an XGBoost model trained to predict arousal).</li> </ul> </li> </ol>"},{"location":"config/#label-configuration","title":"Label Configuration","text":"<ol> <li><code>label_columns</code>:<ul> <li>List of labels (columns) in the dataset that represent emotional states.</li> <li>Example: <code>[\"valence\", \"arousal\"]</code> specifies these two emotions as labels.</li> </ul> </li> <li><code>target_label</code>:<ul> <li>The label the model will predict.</li> <li>Only one label can be selected at a time (e.g., <code>\"arousal\"</code> for predicting arousal levels).</li> </ul> </li> </ol>"},{"location":"config/#configuration-for-combined-data","title":"Configuration for Combined Data","text":"<ol> <li><code>time_window</code>:<ul> <li>Defines the time range (in minutes) before and after a self-report to extract accelerometer data.</li> <li>Example: <code>2</code> means extract 2 minutes of data before and after each self-report.</li> </ul> </li> </ol>"},{"location":"config/#configuration-for-feature-extraction","title":"Configuration for Feature Extraction","text":"<ol> <li><code>window_length</code>:<ul> <li>Length of the time window (in seconds) used to segment accelerometer data for feature extraction.</li> <li>Example: <code>60</code> means divide the data into 1-minute windows.</li> </ul> </li> <li><code>window_step_size</code>:<ul> <li>Step size (in seconds) for moving the window forward.</li> <li>Smaller values overlap windows more, providing more data segments.</li> </ul> </li> <li><code>data_frequency</code>:<ul> <li>Sampling rate of the accelerometer data, in Hz.</li> <li>Example: <code>25</code> means the device records 25 data points per second.</li> </ul> </li> <li><code>selected_domains</code>:<ul> <li>Specifies which feature domains to extract.</li> <li>Options: <code>\"time_domain\"</code>, <code>\"spatial\"</code>, <code>\"frequency\"</code>, <code>\"statistical\"</code>, <code>\"wavelet\"</code>.</li> <li>Example: <code>[\"time_domain\", \"frequency\"]</code> means only extract features from these two domains. <code>None</code> extracts all domains.</li> </ul> </li> <li><code>include_magnitude</code>:<ul> <li>Whether to include magnitude-based features (combining x, y, z axes into one measurement).</li> <li>Example: <code>True</code> includes magnitude features.</li> </ul> </li> </ol>"},{"location":"config/#configuration-for-low-pass-filter","title":"Configuration for Low-Pass Filter","text":"<ol> <li><code>cutoff_frequency</code>:<ul> <li>Frequency limit for the low-pass filter (in Hz).</li> <li>Removes high-frequency noise while keeping important movement data below this frequency.</li> </ul> </li> <li><code>order</code>:<ul> <li>Order of the low-pass filter, determining how sharply it removes unwanted frequencies.</li> <li>Example: <code>4</code> creates a smooth filter with a moderate cutoff.</li> </ul> </li> </ol>"},{"location":"config/#configuration-for-scaling","title":"Configuration for Scaling","text":"<ol> <li><code>scaler_type</code>:<ul> <li>Type of scaler used to standardize or normalize data.</li> <li>Options:<ul> <li><code>\"standard\"</code>: Centers the data to have a mean of 0 and a standard deviation of 1.</li> <li><code>\"minmax\"</code>: Scales the data to a range of 0 to 1.</li> <li><code>\"none\"</code>: No scaling applied.</li> </ul> </li> </ul> </li> </ol>"},{"location":"config/#configuration-for-pca","title":"Configuration for PCA","text":"<ol> <li><code>apply_pca</code>:<ul> <li>Whether to apply Principal Component Analysis (PCA) to reduce the number of features.</li> <li>Example: <code>False</code> skips PCA.</li> </ul> </li> <li><code>pca_variance</code>:<ul> <li>The amount of variance to retain when applying PCA.</li> <li>Example: <code>0.95</code> keeps 95% of the information in the data.</li> </ul> </li> </ol>"},{"location":"config/#configuration-for-model-training","title":"Configuration for Model Training","text":"<ol> <li><code>classifier</code>:<ul> <li>The machine learning model to use for training.</li> <li>Options: <code>\"xgboost\"</code>, <code>\"svm\"</code>, <code>\"randomforest\"</code>.</li> <li>Example: <code>\"xgboost\"</code> uses XGBoost for training.</li> </ul> </li> </ol>"},{"location":"config/#configuration-for-hyperparameter-tuning","title":"Configuration for Hyperparameter Tuning","text":"<ol> <li><code>n_splits</code>:<ul> <li>Number of folds for cross-validation.</li> <li>Example: <code>5</code> means split the data into 5 groups for evaluation.</li> </ul> </li> <li><code>n_iter</code>:<ul> <li>Number of iterations for hyperparameter tuning.</li> <li>Example: <code>30</code> tests 30 combinations of settings.</li> </ul> </li> <li><code>n_jobs</code>:<ul> <li>Number of CPU cores to use for parallel processing.</li> <li>Example: <code>1</code> uses all available cores.</li> </ul> </li> <li><code>n_points</code>:<ul> <li>Number of hyperparameter combinations to test in parallel.</li> <li>Example: <code>1</code> tests one combination at a time.</li> </ul> </li> <li><code>param_space</code>:<ul> <li>Custom hyperparameter space for the selected model.</li> <li>Example:<ul> <li><code>\"learning_rate\": (0.05, 0.2)</code> specifies the range of learning rates to test for the XGBoost model.</li> <li>Set to <code>None</code> to use default hyperparameters defined in the <code>TrainModel</code> class.</li> </ul> </li> </ul> </li> </ol>"},{"location":"gettingstarted/","title":"Getting Started with the Emotion Recognition Pipeline","text":"<p>Welcome to the Emotion Recognition Pipeline! This guide will help you install, configure, and use the pipeline to analyze movement data and recognize emotions efficiently.</p>"},{"location":"gettingstarted/#1-installation","title":"1. Installation","text":""},{"location":"gettingstarted/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python: Version 3.8 or higher.</li> <li>Environment: It is recommended to create a virtual environment for managing dependencies.</li> </ul> <pre><code>python -m venv env\nsource env/bin/activate  # On Windows: env\\Scripts\\activate\n</code></pre>"},{"location":"gettingstarted/#steps","title":"Steps","text":"<ol> <li> <p>Clone the repository:    <pre><code>git clone https://github.com/&lt;your-username&gt;/emotion-recognition-pipeline.git\ncd emotion-recognition-pipeline\n</code></pre></p> </li> <li> <p>Install dependencies:    <pre><code>pip install -r requirements.txt\n</code></pre></p> </li> </ol>"},{"location":"gettingstarted/#2-how-data-processing-works","title":"2. How Data Processing Works","text":"<p>Data analysis typically follows a structured workflow, consisting of four major stages: Data Acquisition, Data Preprocessing, Feature Extraction, and Model Training &amp; Evaluation. Here's a brief overview of these stages and how the pipeline fits into this process.</p> <p></p>"},{"location":"gettingstarted/#21-data-acquisition","title":"2.1. Data Acquisition","text":"<p>In this stage, raw data is collected from various sources. For this pipeline:</p> <ul> <li> <p>Data Sources: Accelerometer measurements and self-reports.</p> </li> <li> <p>Format: CSV files containing timestamped accelerometer readings (<code>x</code>, <code>y</code>, <code>z</code>) and self-report labels (e.g., <code>arousal</code>, <code>valence</code>).</p> </li> </ul> <p>The pipeline begins with the ImportData class to load raw data into a structured format.</p>"},{"location":"gettingstarted/#22-data-preprocessing","title":"2.2. Data Preprocessing","text":"<p>Raw data often contains noise, inconsistencies, or irrelevant information. This stage involves:</p> <ol> <li> <p>Synchronization: Combining accelerometer and self-report data using timestamps and a defined time window.</p> </li> <li> <p>Filtering: Removing high-frequency noise using a low-pass filter.</p> </li> <li> <p>Scaling: Normalizing accelerometer data for consistent feature computation.</p> </li> </ol> <p>The pipeline includes:</p> <ul> <li> <p><code>01_combining_dataframes_pipeline.py</code>: Synchronizes raw data into a combined dataset.</p> </li> <li> <p>LowPassFilter and ScaleXYZData classes for filtering and scaling.</p> </li> </ul>"},{"location":"gettingstarted/#23-feature-extraction","title":"2.3. Feature Extraction","text":"<p>This stage converts raw accelerometer data into meaningful features representing movement patterns. Features are grouped into domains such as: - Time Domain: Mean, variance, RMS, skewness, etc.</p> <ul> <li> <p>Frequency Domain: Spectral entropy, dominant frequency, etc.</p> </li> <li> <p>Spatial Features: Euclidean norm, tilt angles, etc.</p> </li> </ul> <p>The pipeline uses:</p> <ul> <li> <p><code>02_feature_extraction_pipeline.py</code>: Extracts features based on your configuration in <code>_config.py</code>.</p> </li> <li> <p>ExtractFeatures class: Handles computation across multiple feature domains.</p> </li> </ul>"},{"location":"gettingstarted/#24-model-training-evaluation","title":"2.4. Model Training &amp; Evaluation","text":"<p>With extracted features, this stage trains a machine learning model to classify emotions:</p> <ol> <li> <p>Model Training: Uses classifiers like RandomForest, SVM, or XGBoost.</p> </li> <li> <p>Hyperparameter Optimization: Employs Bayesian search for tuning.</p> </li> <li> <p>Evaluation: Generates performance metrics and feature importance.</p> </li> </ol> <p>The pipeline uses: - <code>03_training_model_pipeline.py</code>: Trains a model using extracted features. - TrainModel class: Handles training, hyperparameter tuning, and evaluation.</p>"},{"location":"gettingstarted/#3-how-to-combine-dataframes","title":"3. How to combine Dataframes","text":""},{"location":"gettingstarted/#4-how-to-extract-features","title":"4. How to extract Features?","text":""},{"location":"gettingstarted/#5-how-to-train-a-model","title":"5. How to train a Model","text":""},{"location":"gettingstarted/#6-how-to-classify-movement-data","title":"6. How to classify Movement Data","text":""},{"location":"gettingstarted/#7-support","title":"7. Support","text":"<p>For detailed instructions or issues, refer to the repository documentation or contact us at <code>&lt;support-email&gt;</code>.</p> <p>This additional section provides clarity about the general data analysis process and highlights how the pipeline fits into this workflow. Let me know if you need further refinements!</p>"},{"location":"input_data_selfreports/","title":"Input data selfreports","text":""},{"location":"input_data_selfreports/#1-self-reports-data","title":"1. Self-Reports Data","text":""},{"location":"input_data_selfreports/#what-it-is","title":"What It Is:","text":"<p>This dataset contains participants' self-reports about their emotions (e.g., arousal or valence) and the times when they submitted these reports.</p>"},{"location":"input_data_selfreports/#required-format","title":"Required Format:","text":"<ul> <li>Columns:<ul> <li><code>participantId</code>: A unique identifier for the participant.</li> <li><code>timeOfNotification</code>: The timestamp of the self-report (in milliseconds or ISO format).</li> <li>Emotion labels (e.g., <code>valence</code>, <code>arousal</code>): The emotional states reported by participants.</li> </ul> </li> </ul>"},{"location":"input_data_selfreports/#example-structure","title":"Example Structure:","text":"participantId timeOfNotification valence arousal 1 1672012800000 Positive High 1 1672013400000 Neutral Medium"},{"location":"input_data_selfreports/#how-to-transform-your-data","title":"How to Transform Your Data:","text":"<p>If your data uses a different timestamp format or column names, here\u2019s how to adjust it:</p> <pre><code>import pandas as pd\n\n# Load the self-reports data\ndf_reports = pd.read_csv(\"path_to_self_reports.csv\")\n\n# Rename columns if necessary\ndf_reports.rename(columns={\n    \"timestamp_column\": \"timeOfNotification\",\n    \"emotion_column_1\": \"valence\",\n    \"emotion_column_2\": \"arousal\"\n}, inplace=True)\n\n# Convert timestamp to datetime format if needed\ndf_reports[\"timeOfNotification\"] = pd.to_datetime(df_reports[\"timeOfNotification\"], unit=\"ms\")\n\nprint(df_reports.head())\n</code></pre>"},{"location":"installation/","title":"How to install","text":""},{"location":"pipelines_classifying_data/","title":"Classify Movement Data","text":""},{"location":"pipelines_classifying_data/#general-explanation","title":"General Explanation","text":"<p>The Analyzing Data Pipeline is designed to preprocess, extract features, and classify emotions based on accelerometer data. This pipeline simplifies the analysis process by automating tasks like filtering noise, normalizing data, extracting meaningful features, and applying machine learning models.</p> Click to view diagram <p></p>"},{"location":"pipelines_classifying_data/#use-cases","title":"Use Cases","text":"<p>Emotion Recognition: Classify emotions (e.g., arousal and valence levels) using pre-trained machine learning models on movement data.</p>"},{"location":"pipelines_classifying_data/#input-configuration","title":"Input &amp; Configuration","text":"<p>Raw Accelerometer Data containing xyz data with timestamps and participantid A pre-trained Model which is trained with the same features which will be extracted in the pipeline in a later step</p> Input Description Raw Accelerometer Data Contains <code>x</code>, <code>y</code>, <code>z</code> axis data with <code>timestamps</code> and <code>participantId</code>. Pre-trained Model A model trained with the same features that will be extracted in the pipeline during a later step. Configuration Description <code>cutoff_frequency</code> The cutoff frequency for the low-pass filter. <code>data_frequency</code> The sampling rate of the accelerometer data in Hz. <code>order</code> The order of the low-pass filter. <code>scaler_type</code> The type of scaler to normalize or standardize the data. Options: <code>\"standard\"</code>, <code>\"minmax\"</code>, or <code>\"none\"</code>. <code>window_length</code> The length of the sliding window for feature extraction (in seconds). <code>window_step_size</code> The step size for moving the sliding window (in seconds). <code>selected_domains</code> List of feature domains to include for extraction (e.g., <code>['time_domain', 'frequency']</code>). <code>include_magnitude</code> Whether to include magnitude-based features during feature extraction. Options: <code>True</code> or <code>False</code>. <code>model_path</code> Path to the pre-trained model for classification."},{"location":"pipelines_classifying_data/#output","title":"Output","text":"<ul> <li>A CSV file with all extracted features and predicted emotions as columns.</li> <li>Each row represents a time window during which emotions were classified.</li> </ul> Time Window Extracted Features Predicted Emotion Time Window 1 Feature values for window 1 Predicted emotion 1 Time Window 2 Feature values for window 2 Predicted emotion 2 Time Window 3 Feature values for window 3 Predicted emotion 3"},{"location":"pipelines_combine_dataframes/","title":"Combine Dataframes","text":""},{"location":"pipelines_combine_dataframes/#general-explanation","title":"General Explanation","text":"<p>The Combining DataFrames Pipeline is designed to preprocess and merge raw accelerometer data and self-reports into a unified dataset. It simplifies the process of aligning timestamps, aggregating movement data within a specified time window, and dynamically adding contextual labels from self-reports. This pipeline is modular, making it reusable and adaptable for different stages of analysis, from preprocessing to model training.</p> Click to view diagram <p></p>"},{"location":"pipelines_combine_dataframes/#use-case","title":"Use Case","text":"<p>Combine raw accelerometer and self-reports data: Create a structured dataset ready for feature extraction or model training. Preprocess data consistently: Ensure uniform handling of timestamps, labels, and accelerometer data across different datasets. Prepare data for exploratory or predictive analysis: Use the resulting combined dataset as the foundation for understanding relationships between movement patterns and self-reported labels.</p>"},{"location":"pipelines_combine_dataframes/#inputs","title":"Inputs","text":"Input Type Description Raw Accelerometer Data CSV file with columns for x, y, z axes, timestamps (timeOfNotification), and participantId. Self-Reports Data CSV file with columns for timeOfNotification, participantId, and emotion labels (e.g., arousal, valence). Configuration Settings - <code>time_window</code>: Specifies the size (in minutes) of the time window for aggregating accelerometer data around each self-report. - <code>label_columns</code>: A list of columns from the self-reports dataset to use as labels (e.g., [\"arousal\", \"valence\"])."},{"location":"pipelines_combine_dataframes/#outputs","title":"Outputs","text":"<p>It Outputs a Dataset with these Columns:</p> Column Name Description participantId Participant identifier. selfreport_time Timestamp of the self-report. accel_time Timestamp of the accelerometer reading. x Accelerometer reading for the x axis. y Accelerometer reading for the y axis. z Accelerometer reading for the z axis. Emotion labels Emotion labels from <code>label_columns</code>. groupid A unique identifier for each group of self-report and its corresponding accelerometer data."},{"location":"pipelines_complete_pipeline/","title":"End To End","text":""},{"location":"pipelines_complete_pipeline/#general-explanation","title":"General Explanation","text":"<p>This pipeline is designed for users who want to train a machine learning model for emotion recognition in one complete process. It takes raw accelerometer data (x, y, z, and timestamps) and self-reports as input, processes the data through several steps, and outputs a trained model along with a detailed report on its performance.</p> <p>The pipeline automates all necessary preprocessing steps, including combining data, filtering noise, scaling, extracting features, and training the model. It is ideal for users looking for a straightforward, end-to-end solution without intermediate checkpoints. By the end of the pipeline, users receive:</p> <ol> <li> <p>A fully trained and optimized model ready for use.</p> </li> <li> <p>A report containing model performance metrics, hyperparameter details, and feature importances.</p> </li> </ol> <p>This setup is especially useful for researchers or analysts who need a training pipeline for emotion classification based on accelerometer data combined with self-reports.</p> Click to view diagram <p></p>"},{"location":"pipelines_complete_pipeline/#inputs-configuration","title":"Inputs &amp; Configuration","text":"Input Type Description Raw Accelerometer Data CSV file with columns for x, y, z axes, timestamps (timeOfNotification), and participantId. Self-Reports Data CSV file with columns for timeOfNotification, participantId, and emotion labels (e.g., arousal, valence). <p>Configuration</p> <p>For the configuration please see: configuration file</p>"},{"location":"pipelines_complete_pipeline/#outputs","title":"Outputs","text":"Output Description Trained Model A serialized model file (e.g., <code>xgboost_best_model_target.pkl</code>) saved with the target name for easy identification. Classification Report A JSON file containing detailed metrics like precision, recall, and F1-score."},{"location":"pipelines_feature_extraction/","title":"Feature Extraction","text":""},{"location":"pipelines_feature_extraction/#general-explanation","title":"General Explanation","text":"<p>This modular pipeline processes movement data from accelerometers to extract features that can be used for emotion recognition and other analyses. It consists of predefined pipeline components, each represented by a class. These components include data import, filtering, scaling, and feature extraction. The modular structure allows users to set \"checkpoints\" at various stages, making it easy to reuse intermediate outputs (e.g., scaled data or extracted features) for different configurations or experiments.</p> Click to view diagram <p></p>"},{"location":"pipelines_feature_extraction/#use-case","title":"Use Case","text":"<p>Extracting meaningful features from raw accelerometer data for model training.</p> <p>Preparing data for supervised learning.</p> <p>Experimenting with different preprocessing steps (e.g., scaling methods, time windows or cutoff frequencies).</p>"},{"location":"pipelines_feature_extraction/#input-and-configuration-data","title":"Input and Configuration Data","text":"Input/Configuration Description Combined Dataframe Pre-combined dataset of accelerometer and self-reports data. Raw Accelerometer Data CSV file with columns for x, y, z axes, timestamps (timeOfNotification), and participantId. <code>accel_path</code> Path to the raw accelerometer data file. <code>reports_path</code> Path to the self-reports data file (optional). <code>combined_data_path</code> Path to the pre-combined dataset (optional). <code>features_data_path</code> Path to the pre-extracted features file (optional). <code>cutoff_frequency</code> Cutoff frequency for the low-pass filter (default: 5 Hz). <code>data_frequency</code> Sampling rate of the accelerometer data (default: 25 Hz). <code>order</code> Filter order (default: 4). <code>scaler_type</code> Type of scaling to apply to the accelerometer data: - 'standard': StandardScaler (zero mean, unit variance). - 'minmax': MinMaxScaler (scales to a [0,1] range). - 'none': No scaling applied. <code>window_length</code> Length of the sliding window (in seconds, e.g., 60 seconds). <code>window_step_size</code> Step size for the sliding window (in seconds, e.g., 30 seconds). <code>selected_domains</code> Domains to extract features from: - Options: 'time_domain', 'spatial', 'frequency', 'statistical', 'wavelet'. - Default: None (extract all domains). <code>include_magnitude</code> Whether to include magnitude-based features. <code>label_columns</code> Emotion label columns to include in the output (e.g., arousal, valence)."},{"location":"pipelines_feature_extraction/#outputs","title":"Outputs","text":"<p>It Outputs a Dataset with these Columns:'time_domain', 'spatial', 'frequency', 'statistical', 'wavelet'</p>"},{"location":"pipelines_feature_extraction/#time-domain-features","title":"Time Domain Features","text":"Click to view Time Domain Features <ul> <li>Mean (x, y, z, magnitude) </li> <li>Standard Deviation (x, y, z, magnitude) </li> <li>Variance (x, y, z, magnitude) </li> <li>Root Mean Square (RMS) (x, y, z, magnitude) </li> <li>Maximum (x, y, z, magnitude) </li> <li>Minimum (x, y, z, magnitude) </li> <li>Peak-to-Peak Amplitude (x, y, z, magnitude) </li> <li>Skewness (x, y, z, magnitude) </li> <li>Kurtosis (x, y, z, magnitude) </li> <li>Zero-Crossing Rate (x, y, z, magnitude) </li> <li>Signal Magnitude Area (SMA) </li> </ul>"},{"location":"pipelines_feature_extraction/#frequency-domain-features","title":"Frequency Domain Features","text":"Click to view Frequency Domain Features <ul> <li>Dominant Frequency (x, y, z, magnitude) </li> <li>Spectral Entropy (x, y, z, magnitude) </li> <li>Power Spectral Density (PSD) Mean (x, y, z, magnitude) </li> <li>Energy (x, y, z, magnitude) </li> <li>Bandwidth (x, y, z, magnitude) </li> <li>Spectral Centroid (x, y, z, magnitude) </li> </ul>"},{"location":"pipelines_feature_extraction/#statistical-features","title":"Statistical Features","text":"Click to view Statistical Features <ul> <li>25th Percentile (x, y, z, magnitude) </li> <li>75th Percentile (x, y, z, magnitude) </li> </ul>"},{"location":"pipelines_feature_extraction/#wavelet-domain-features","title":"Wavelet Domain Features","text":"Click to view Wavelet Domain Features <ul> <li>Wavelet Energy (Approximation) (x, y, z, magnitude) </li> </ul>"},{"location":"pipelines_feature_extraction/#spatial-features","title":"Spatial Features","text":"Click to view Spatial Features <ul> <li>Euclidean Norm (Magnitude) </li> <li>Mean Tilt Angle (Pitch, Roll) </li> <li>Correlation between Axes (x-y, x-z, y-z) </li> </ul>"},{"location":"pipelines_train_model/","title":"Train Model","text":""},{"location":"pipelines_train_model/#general-explanation","title":"General Explanation","text":"<p>This pipeline is designed for analyzing and classifying movement data efficiently and modularly. It allows users to preprocess raw accelerometer data, apply dimensionality reduction with PCA, and train machine learning models with hyperparameter optimization. The modular design ensures flexibility, enabling users to set \"checkpoints\" to reuse preprocessed or feature-engineered data across different experiments.</p> Click to view diagram <p></p>"},{"location":"pipelines_train_model/#use-cases","title":"Use Cases","text":"<p>Training a Machine Learning Model: Train a classification model using pre-extracted features and save the best-performing model.</p> <p>Experimenting with Different Models: Reuse the same preprocessed feature set to train multiple models with different configurations.</p>"},{"location":"pipelines_train_model/#input-configuration","title":"Input &amp; Configuration","text":"Input Description Features Dataset (CSV) A CSV file with pre-calculated features, including columns for the features themselves, any relevant metadata, and a target label. Configuration Description <code>use_accel</code> Whether to load raw accelerometer data (used only for preprocessing outside this pipeline). <code>use_reports</code> Whether to include self-reports data. (Not required for feature-based pipelines). <code>use_combined</code> Whether to use combined data (raw accelerometer + self-reports). <code>use_features</code> Whether to load a pre-extracted feature dataset. Must be set to True for this pipeline. <code>apply_pca</code> Whether to apply PCA for dimensionality reduction. <code>pca_variance</code> Variance threshold for PCA, specifying how much of the total variance should be retained. <code>classifier</code> The type of model to train: xgboost, svm, or randomforest. <code>target_label</code> The column name in the dataset to use as the target variable. <code>selected_domains</code> Domains of features to include in the training (e.g., time, frequency). All domains by default. <code>n_splits</code> Number of cross-validation splits for Bayesian hyperparameter tuning. <code>n_iter</code> Number of iterations for the hyperparameter search. <code>n_jobs</code> Number of parallel jobs for Bayesian optimization. <code>n_points</code> Number of parameter settings sampled in parallel during optimization."},{"location":"pipelines_train_model/#outputs","title":"Outputs","text":"Output Description Trained Model A serialized model file (e.g., <code>xgboost_best_model_target.pkl</code>) saved with the target name for easy identification. Classification Report A JSON file containing detailed metrics like precision, recall, and F1-score."}]}